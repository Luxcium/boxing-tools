Ok I was a little frustrated as it was not what I was expecting... Obviously it was an intermediate step...

What I do understand now is that either we would have had to wait longer to get better content moderation or we could have it faster so that OpenAI could, probably, gather the necessary data to have a more nuanced approach...

I now understand that it was probably not OpenAI's goal to build an AI Agent that is so limited, but rather like a kid who doesn't start using a bicycle right away but needs training wheels to get up to the task...

This is meeting my expectations. The AI doesn't make definitive claims, but it offers educated guesses that are nuanced, as if it were to make a mistake, this same text would still be valid despite being incorrect because of how it is phrased and the choice of words...

Give me a plain old normal old looking white shoe
